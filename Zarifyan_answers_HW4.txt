Зарифян Маша

Сравнив полученные результаты с результатами interest, мы видим, что результат получился в разы хуже ( если у interest precision = 0.769, а  recall = 0.738, 
то, классифицируя слово "поле" с помощью алгоритма One-R,  мы получаем всего лишь следующие результаты: precision = 0,499, recall = 0,480.
Мой датасет не очень хорошо сбалансирован по значениям: более-менее сбалансированы 1,2,3,4 значения, остальные же значения менее частотны. Лучше всего 
классифицируется значение 1 - прототипическое значение слова "поле", но, в то же время, бОльшую часть значений алгоритм и ошибочно отнёс к значению 1. 
Значение 2 распознается чуть хуже - 24  раза алгоритм правильно определил класс, а 21 раз ошибочно отнес их к значению-1. 

После добавления ключевых слов ничего не изменилось - результаты остались такими же. Я, кажется, так и не смогла выделить ключевые слова правильно - они все 
оказались довольно редки. Как мне кажется, такие фичи, как соседи слова слева и справа были недостаточны, так как во многих случаях соседями 
нашего классифицируемого слова оказываются служебные части речи -  предлоги, союзы, частицы; которые не несут на себе никакого смысла и ничего не говорят нам о значении этого слова.
Например, в предложении "Человек надел шляпу с полями и пиджак" необходимо "захватывать" хотя бы по три соседа слева и три справа, чтобы более 
качественно определить значение слова. 

Если предсказывать значение слова с помощью логистической регрессии, мы видим, что результаты чуть улучшатся: precision = 0.515, а  recall = 0.52
При этом значительно хуже угадывается первое значение слова, а 2,3,4, 10, 11  - лучше:


=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,361    0,129    0,550      0,361    0,436      0,266    0,737     0,513     1
                 0,622    0,213    0,459      0,622    0,528      0,371    0,771     0,520     2
                 0,727    0,114    0,558      0,727    0,632      0,554    0,885     0,708     3
                 0,400    0,103    0,452      0,400    0,424      0,312    0,747     0,424     4
                 0,000    0,005    0,000      0,000    0,000      -0,009   0,616     0,027     5
                 0,200    0,015    0,250      0,200    0,222      0,206    0,821     0,171     6
                 0,000    0,005    0,000      0,000    0,000      -0,005   0,563     0,011     7
                 1,000    0,005    0,875      1,000    0,933      0,933    0,997     0,875     10
                 0,800    0,016    0,727      0,800    0,762      0,750    0,947     0,821     11
Weighted Avg.    0,520    0,126    0,515      0,520    0,507      0,386    0,790     0,541     



  a  b  c  d  e  f  g  h  i   <-- classified as
 22 21  7  6  0  1  0  1  3 |  a = 1
  8 28  2  6  0  1  0  0  0 |  b = 2
  1  4 24  4  0  0  0  0  0 |  c = 3
  5  6  8 14  1  0  1  0  0 |  d = 4
  0  0  2  1  0  0  0  0  0 |  e = 5
  2  2  0  0  0  1  0  0  0 |  f = 6
  0  0  0  0  0  1  0  0  0 |  g = 7
  0  0  0  0  0  0  0  7  0 |  h = 10
  2  0  0  0  0  0  0  0  8 |  i = 11
  
  

  RandomForest еще улучшает наш результат: precision = 0.58, a recall = 0.57. И лучше распознает 11 значение. 
  
  
  === Classifier model (full training set) ===

RandomForest

Bagging with 100 iterations and base learner

weka.classifiers.trees.RandomTree -K 0 -M 1.0 -V 0.001 -S 1 -do-not-check-capabilities

Time taken to build model: 0.29 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         115               57.5    %
Incorrectly Classified Instances        85               42.5    %
Kappa statistic                          0.4482
Mean absolute error                      0.1386
Root mean squared error                  0.2537
Relative absolute error                 78.0564 %
Root relative squared error             85.3676 %
Total Number of Instances              200     

=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,705    0,360    0,462      0,705    0,558      0,319    0,730     0,535     1
                 0,578    0,103    0,619      0,578    0,598      0,487    0,794     0,631     2
                 0,636    0,048    0,724      0,636    0,677      0,620    0,878     0,773     3
                 0,257    0,030    0,643      0,257    0,367      0,338    0,794     0,510     4
                 0,000    0,005    0,000      0,000    0,000      -0,009   0,389     0,016     5
                 0,000    0,005    0,000      0,000    0,000      -0,011   0,897     0,130     6
                 0,000    0,000    0,000      0,000    0,000      0,000    0,106     0,005     7
                 1,000    0,005    0,875      1,000    0,933      0,933    1,000     1,000     10
                 0,900    0,016    0,750      0,900    0,818      0,811    0,996     0,938     11
Weighted Avg.    0,575    0,147    0,580      0,575    0,554      0,441    0,799     0,607     

=== Confusion Matrix ===

  a  b  c  d  e  f  g  h  i   <-- classified as
 43 10  2  3  0  1  0  1  1 |  a = 1
 17 26  1  1  0  0  0  0  0 |  b = 2
 10  0 21  1  0  0  0  0  1 |  c = 3
 17  3  5  9  1  0  0  0  0 |  d = 4
  2  0  0  0  0  0  0  0  1 |  e = 5
  2  3  0  0  0  0  0  0  0 |  f = 6
  1  0  0  0  0  0  0  0  0 |  g = 7
  0  0  0  0  0  0  0  7  0 |  h = 10
  1  0  0  0  0  0  0  0  9 |  i = 11
